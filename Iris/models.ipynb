{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(os.getcwd(), 'iris.data'), names=['sepal_length', 'sepal_width', 'petal_length',\n",
    "                                                                  'petal_width', 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.054000      3.758667     1.198667\n",
       "std        0.828066     0.433594      1.764420     0.763161\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 4) (24, 4) (24, 4)\n",
      "(102,) (24,) (24,)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.16, random_state=3)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.19, random_state=3)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler()\n",
    "y_encoder = LabelEncoder()\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "X_val = X_scaler.transform(X_val)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "y_encoder.fit(y_train)\n",
    "y_train = to_categorical(y_encoder.transform(y_train))\n",
    "y_val = to_categorical(y_encoder.transform(y_val))\n",
    "y_test = to_categorical(y_encoder.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [1000$]')\n",
    "    plt.plot(history.epoch, np.array(history.history['loss']),\n",
    "           label='Train Loss')\n",
    "    plt.plot(history.epoch, np.array(history.history['val_loss']),\n",
    "           label = 'Val loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True)\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(4, input_shape=(4,), kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dense(3, kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Activation('softmax')\n",
    "])\n",
    "optimizer = tf.train.AdamOptimizer(0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102 samples, validate on 24 samples\n",
      "Epoch 1/1000\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 1.0196 - acc: 0.3333 - val_loss: 0.9455 - val_acc: 0.3750\n",
      "Epoch 2/1000\n",
      "102/102 [==============================] - 0s 89us/step - loss: 1.0105 - acc: 0.4020 - val_loss: 0.9365 - val_acc: 0.4583\n",
      "Epoch 3/1000\n",
      "102/102 [==============================] - 0s 147us/step - loss: 1.0016 - acc: 0.4216 - val_loss: 0.9283 - val_acc: 0.4167\n",
      "Epoch 4/1000\n",
      "102/102 [==============================] - 0s 134us/step - loss: 0.9935 - acc: 0.4510 - val_loss: 0.9204 - val_acc: 0.4167\n",
      "Epoch 5/1000\n",
      "102/102 [==============================] - 0s 169us/step - loss: 0.9849 - acc: 0.5000 - val_loss: 0.9129 - val_acc: 0.4167\n",
      "Epoch 6/1000\n",
      "102/102 [==============================] - 0s 177us/step - loss: 0.9773 - acc: 0.5196 - val_loss: 0.9057 - val_acc: 0.4583\n",
      "Epoch 7/1000\n",
      "102/102 [==============================] - 0s 175us/step - loss: 0.9693 - acc: 0.5784 - val_loss: 0.8992 - val_acc: 0.5417\n",
      "Epoch 8/1000\n",
      "102/102 [==============================] - 0s 126us/step - loss: 0.9626 - acc: 0.6471 - val_loss: 0.8926 - val_acc: 0.5417\n",
      "Epoch 9/1000\n",
      "102/102 [==============================] - 0s 163us/step - loss: 0.9555 - acc: 0.6471 - val_loss: 0.8862 - val_acc: 0.5833\n",
      "Epoch 10/1000\n",
      "102/102 [==============================] - 0s 134us/step - loss: 0.9487 - acc: 0.6471 - val_loss: 0.8801 - val_acc: 0.5833\n",
      "Epoch 11/1000\n",
      "102/102 [==============================] - 0s 139us/step - loss: 0.9420 - acc: 0.6471 - val_loss: 0.8741 - val_acc: 0.5833\n",
      "Epoch 12/1000\n",
      "102/102 [==============================] - 0s 108us/step - loss: 0.9355 - acc: 0.6961 - val_loss: 0.8683 - val_acc: 0.5833\n",
      "Epoch 13/1000\n",
      "102/102 [==============================] - 0s 139us/step - loss: 0.9292 - acc: 0.6961 - val_loss: 0.8630 - val_acc: 0.5833\n",
      "Epoch 14/1000\n",
      "102/102 [==============================] - 0s 154us/step - loss: 0.9232 - acc: 0.7157 - val_loss: 0.8575 - val_acc: 0.5833\n",
      "Epoch 15/1000\n",
      "102/102 [==============================] - 0s 154us/step - loss: 0.9173 - acc: 0.7157 - val_loss: 0.8523 - val_acc: 0.5833\n",
      "Epoch 16/1000\n",
      "102/102 [==============================] - 0s 186us/step - loss: 0.9114 - acc: 0.7157 - val_loss: 0.8471 - val_acc: 0.5833\n",
      "Epoch 17/1000\n",
      "102/102 [==============================] - 0s 141us/step - loss: 0.9058 - acc: 0.7157 - val_loss: 0.8421 - val_acc: 0.5833\n",
      "Epoch 18/1000\n",
      "102/102 [==============================] - 0s 178us/step - loss: 0.8999 - acc: 0.7255 - val_loss: 0.8373 - val_acc: 0.5833\n",
      "Epoch 19/1000\n",
      "102/102 [==============================] - 0s 181us/step - loss: 0.8944 - acc: 0.7255 - val_loss: 0.8327 - val_acc: 0.5833\n",
      "Epoch 20/1000\n",
      "102/102 [==============================] - 0s 114us/step - loss: 0.8888 - acc: 0.7353 - val_loss: 0.8283 - val_acc: 0.5833\n",
      "Epoch 21/1000\n",
      "102/102 [==============================] - 0s 157us/step - loss: 0.8834 - acc: 0.7451 - val_loss: 0.8238 - val_acc: 0.5833\n",
      "Epoch 22/1000\n",
      "102/102 [==============================] - 0s 121us/step - loss: 0.8780 - acc: 0.7451 - val_loss: 0.8195 - val_acc: 0.5833\n",
      "Epoch 23/1000\n",
      "102/102 [==============================] - 0s 149us/step - loss: 0.8725 - acc: 0.7451 - val_loss: 0.8153 - val_acc: 0.5833\n",
      "Epoch 24/1000\n",
      "102/102 [==============================] - 0s 183us/step - loss: 0.8670 - acc: 0.7549 - val_loss: 0.8113 - val_acc: 0.5833\n",
      "Epoch 25/1000\n",
      "102/102 [==============================] - 0s 114us/step - loss: 0.8617 - acc: 0.7549 - val_loss: 0.8072 - val_acc: 0.5833\n",
      "Epoch 26/1000\n",
      "102/102 [==============================] - 0s 157us/step - loss: 0.8566 - acc: 0.7549 - val_loss: 0.8031 - val_acc: 0.5833\n",
      "Epoch 27/1000\n",
      "102/102 [==============================] - 0s 119us/step - loss: 0.8513 - acc: 0.7549 - val_loss: 0.7992 - val_acc: 0.6250\n",
      "Epoch 28/1000\n",
      "102/102 [==============================] - 0s 147us/step - loss: 0.8463 - acc: 0.7549 - val_loss: 0.7954 - val_acc: 0.6250\n",
      "Epoch 29/1000\n",
      "102/102 [==============================] - 0s 164us/step - loss: 0.8411 - acc: 0.7549 - val_loss: 0.7915 - val_acc: 0.6250\n",
      "Epoch 30/1000\n",
      "102/102 [==============================] - 0s 116us/step - loss: 0.8363 - acc: 0.7549 - val_loss: 0.7875 - val_acc: 0.6250\n",
      "Epoch 31/1000\n",
      "102/102 [==============================] - 0s 131us/step - loss: 0.8315 - acc: 0.7451 - val_loss: 0.7836 - val_acc: 0.6250\n",
      "Epoch 32/1000\n",
      "102/102 [==============================] - 0s 122us/step - loss: 0.8267 - acc: 0.7451 - val_loss: 0.7797 - val_acc: 0.6667\n",
      "Epoch 33/1000\n",
      "102/102 [==============================] - 0s 159us/step - loss: 0.8217 - acc: 0.7451 - val_loss: 0.7759 - val_acc: 0.6667\n",
      "Epoch 34/1000\n",
      "102/102 [==============================] - 0s 116us/step - loss: 0.8167 - acc: 0.7451 - val_loss: 0.7721 - val_acc: 0.6667\n",
      "Epoch 35/1000\n",
      "102/102 [==============================] - 0s 203us/step - loss: 0.8118 - acc: 0.7451 - val_loss: 0.7685 - val_acc: 0.6667\n",
      "Epoch 36/1000\n",
      "102/102 [==============================] - 0s 150us/step - loss: 0.8066 - acc: 0.7549 - val_loss: 0.7649 - val_acc: 0.6667\n",
      "Epoch 37/1000\n",
      "102/102 [==============================] - 0s 158us/step - loss: 0.8016 - acc: 0.7549 - val_loss: 0.7613 - val_acc: 0.6667\n",
      "Epoch 38/1000\n",
      "102/102 [==============================] - 0s 128us/step - loss: 0.7966 - acc: 0.7549 - val_loss: 0.7578 - val_acc: 0.6667\n",
      "Epoch 39/1000\n",
      "102/102 [==============================] - 0s 152us/step - loss: 0.7918 - acc: 0.7549 - val_loss: 0.7543 - val_acc: 0.6667\n",
      "Epoch 40/1000\n",
      "102/102 [==============================] - 0s 116us/step - loss: 0.7871 - acc: 0.7549 - val_loss: 0.7511 - val_acc: 0.6667\n",
      "Epoch 41/1000\n",
      "102/102 [==============================] - 0s 121us/step - loss: 0.7822 - acc: 0.7549 - val_loss: 0.7477 - val_acc: 0.6667\n",
      "Epoch 42/1000\n",
      "102/102 [==============================] - 0s 208us/step - loss: 0.7774 - acc: 0.7549 - val_loss: 0.7444 - val_acc: 0.6667\n",
      "Epoch 43/1000\n",
      "102/102 [==============================] - 0s 153us/step - loss: 0.7728 - acc: 0.7549 - val_loss: 0.7413 - val_acc: 0.6667\n",
      "Epoch 44/1000\n",
      "102/102 [==============================] - 0s 135us/step - loss: 0.7681 - acc: 0.7549 - val_loss: 0.7383 - val_acc: 0.6667\n",
      "Epoch 45/1000\n",
      "102/102 [==============================] - 0s 137us/step - loss: 0.7631 - acc: 0.7549 - val_loss: 0.7354 - val_acc: 0.6667\n",
      "Epoch 46/1000\n",
      "102/102 [==============================] - 0s 136us/step - loss: 0.7584 - acc: 0.7549 - val_loss: 0.7326 - val_acc: 0.6667\n",
      "Epoch 47/1000\n",
      "102/102 [==============================] - 0s 114us/step - loss: 0.7536 - acc: 0.7549 - val_loss: 0.7298 - val_acc: 0.6667\n",
      "Epoch 48/1000\n",
      "102/102 [==============================] - 0s 147us/step - loss: 0.7490 - acc: 0.7549 - val_loss: 0.7272 - val_acc: 0.6667\n",
      "Epoch 49/1000\n",
      "102/102 [==============================] - 0s 113us/step - loss: 0.7444 - acc: 0.7451 - val_loss: 0.7246 - val_acc: 0.6667\n",
      "Epoch 50/1000\n",
      "102/102 [==============================] - 0s 101us/step - loss: 0.7399 - acc: 0.7451 - val_loss: 0.7219 - val_acc: 0.6667\n",
      "Epoch 51/1000\n",
      "102/102 [==============================] - 0s 115us/step - loss: 0.7355 - acc: 0.7549 - val_loss: 0.7192 - val_acc: 0.6667\n",
      "Epoch 52/1000\n",
      "102/102 [==============================] - 0s 142us/step - loss: 0.7312 - acc: 0.7549 - val_loss: 0.7167 - val_acc: 0.6667\n",
      "Epoch 53/1000\n",
      "102/102 [==============================] - 0s 115us/step - loss: 0.7269 - acc: 0.7549 - val_loss: 0.7143 - val_acc: 0.6667\n",
      "Epoch 54/1000\n",
      "102/102 [==============================] - 0s 136us/step - loss: 0.7227 - acc: 0.7647 - val_loss: 0.7118 - val_acc: 0.6667\n",
      "Epoch 55/1000\n",
      "102/102 [==============================] - 0s 161us/step - loss: 0.7186 - acc: 0.7647 - val_loss: 0.7093 - val_acc: 0.6667\n",
      "Epoch 56/1000\n",
      "102/102 [==============================] - 0s 110us/step - loss: 0.7144 - acc: 0.7647 - val_loss: 0.7067 - val_acc: 0.6667\n",
      "Epoch 57/1000\n",
      "102/102 [==============================] - 0s 125us/step - loss: 0.7104 - acc: 0.7647 - val_loss: 0.7042 - val_acc: 0.6667\n",
      "Epoch 58/1000\n",
      "102/102 [==============================] - 0s 123us/step - loss: 0.7063 - acc: 0.7745 - val_loss: 0.7018 - val_acc: 0.6667\n",
      "Epoch 59/1000\n",
      "102/102 [==============================] - 0s 102us/step - loss: 0.7023 - acc: 0.7745 - val_loss: 0.6993 - val_acc: 0.6667\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 139us/step - loss: 0.6983 - acc: 0.7843 - val_loss: 0.6969 - val_acc: 0.6667\n",
      "Epoch 61/1000\n",
      "102/102 [==============================] - 0s 117us/step - loss: 0.6943 - acc: 0.7843 - val_loss: 0.6944 - val_acc: 0.6667\n",
      "Epoch 62/1000\n",
      "102/102 [==============================] - 0s 134us/step - loss: 0.6905 - acc: 0.7843 - val_loss: 0.6919 - val_acc: 0.7083\n",
      "Epoch 63/1000\n",
      "102/102 [==============================] - 0s 108us/step - loss: 0.6868 - acc: 0.7843 - val_loss: 0.6895 - val_acc: 0.7083\n",
      "Epoch 64/1000\n",
      "102/102 [==============================] - 0s 116us/step - loss: 0.6830 - acc: 0.7843 - val_loss: 0.6872 - val_acc: 0.7083\n",
      "Epoch 65/1000\n",
      "102/102 [==============================] - 0s 130us/step - loss: 0.6792 - acc: 0.7843 - val_loss: 0.6848 - val_acc: 0.7083\n",
      "Epoch 66/1000\n",
      "102/102 [==============================] - 0s 146us/step - loss: 0.6755 - acc: 0.7843 - val_loss: 0.6827 - val_acc: 0.7083\n",
      "Epoch 67/1000\n",
      "102/102 [==============================] - 0s 125us/step - loss: 0.6720 - acc: 0.7843 - val_loss: 0.6808 - val_acc: 0.7083\n",
      "Epoch 68/1000\n",
      "102/102 [==============================] - 0s 136us/step - loss: 0.6681 - acc: 0.7745 - val_loss: 0.6788 - val_acc: 0.7083\n",
      "Epoch 69/1000\n",
      "102/102 [==============================] - 0s 153us/step - loss: 0.6644 - acc: 0.7843 - val_loss: 0.6769 - val_acc: 0.7083\n",
      "Epoch 70/1000\n",
      "102/102 [==============================] - 0s 176us/step - loss: 0.6609 - acc: 0.7843 - val_loss: 0.6750 - val_acc: 0.7083\n",
      "Epoch 71/1000\n",
      "102/102 [==============================] - 0s 142us/step - loss: 0.6573 - acc: 0.7941 - val_loss: 0.6732 - val_acc: 0.7083\n",
      "Epoch 72/1000\n",
      "102/102 [==============================] - 0s 144us/step - loss: 0.6541 - acc: 0.7941 - val_loss: 0.6714 - val_acc: 0.7083\n",
      "Epoch 73/1000\n",
      "102/102 [==============================] - 0s 130us/step - loss: 0.6506 - acc: 0.7941 - val_loss: 0.6693 - val_acc: 0.7083\n",
      "Epoch 74/1000\n",
      "102/102 [==============================] - 0s 140us/step - loss: 0.6474 - acc: 0.7941 - val_loss: 0.6674 - val_acc: 0.7083\n",
      "Epoch 75/1000\n",
      "102/102 [==============================] - 0s 111us/step - loss: 0.6443 - acc: 0.7941 - val_loss: 0.6657 - val_acc: 0.7083\n",
      "Epoch 76/1000\n",
      "102/102 [==============================] - 0s 132us/step - loss: 0.6409 - acc: 0.7941 - val_loss: 0.6640 - val_acc: 0.7083\n",
      "Epoch 77/1000\n",
      "102/102 [==============================] - 0s 136us/step - loss: 0.6377 - acc: 0.7941 - val_loss: 0.6620 - val_acc: 0.7083\n",
      "Epoch 78/1000\n",
      "102/102 [==============================] - 0s 128us/step - loss: 0.6348 - acc: 0.7941 - val_loss: 0.6602 - val_acc: 0.7083\n",
      "Epoch 79/1000\n",
      "102/102 [==============================] - 0s 107us/step - loss: 0.6316 - acc: 0.7941 - val_loss: 0.6584 - val_acc: 0.7083\n",
      "Epoch 80/1000\n",
      "102/102 [==============================] - 0s 134us/step - loss: 0.6287 - acc: 0.7941 - val_loss: 0.6568 - val_acc: 0.7083\n",
      "Epoch 81/1000\n",
      "102/102 [==============================] - 0s 141us/step - loss: 0.6260 - acc: 0.7941 - val_loss: 0.6553 - val_acc: 0.7083\n",
      "Epoch 82/1000\n",
      "102/102 [==============================] - 0s 118us/step - loss: 0.6231 - acc: 0.7941 - val_loss: 0.6536 - val_acc: 0.7083\n",
      "Epoch 83/1000\n",
      "102/102 [==============================] - 0s 141us/step - loss: 0.6203 - acc: 0.7941 - val_loss: 0.6514 - val_acc: 0.7083\n",
      "Epoch 84/1000\n",
      "102/102 [==============================] - 0s 139us/step - loss: 0.6176 - acc: 0.8039 - val_loss: 0.6495 - val_acc: 0.7500\n",
      "Epoch 85/1000\n",
      "102/102 [==============================] - 0s 106us/step - loss: 0.6149 - acc: 0.8137 - val_loss: 0.6477 - val_acc: 0.7500\n",
      "Epoch 86/1000\n",
      "102/102 [==============================] - 0s 136us/step - loss: 0.6122 - acc: 0.8137 - val_loss: 0.6460 - val_acc: 0.7917\n",
      "Epoch 87/1000\n",
      "102/102 [==============================] - 0s 103us/step - loss: 0.6096 - acc: 0.8137 - val_loss: 0.6441 - val_acc: 0.7917\n",
      "Epoch 88/1000\n",
      "102/102 [==============================] - 0s 131us/step - loss: 0.6070 - acc: 0.8137 - val_loss: 0.6424 - val_acc: 0.7917\n",
      "Epoch 89/1000\n",
      "102/102 [==============================] - 0s 134us/step - loss: 0.6046 - acc: 0.8137 - val_loss: 0.6409 - val_acc: 0.7917\n",
      "Epoch 90/1000\n",
      "102/102 [==============================] - 0s 125us/step - loss: 0.6020 - acc: 0.8137 - val_loss: 0.6390 - val_acc: 0.7917\n",
      "Epoch 91/1000\n",
      "102/102 [==============================] - 0s 120us/step - loss: 0.5996 - acc: 0.8137 - val_loss: 0.6370 - val_acc: 0.7917\n",
      "Epoch 92/1000\n",
      "102/102 [==============================] - 0s 119us/step - loss: 0.5973 - acc: 0.8137 - val_loss: 0.6354 - val_acc: 0.7917\n",
      "Epoch 93/1000\n",
      "102/102 [==============================] - 0s 153us/step - loss: 0.5949 - acc: 0.8137 - val_loss: 0.6336 - val_acc: 0.7917\n",
      "Epoch 94/1000\n",
      "102/102 [==============================] - 0s 124us/step - loss: 0.5926 - acc: 0.8137 - val_loss: 0.6320 - val_acc: 0.7917\n",
      "Epoch 95/1000\n",
      "102/102 [==============================] - 0s 100us/step - loss: 0.5904 - acc: 0.8137 - val_loss: 0.6305 - val_acc: 0.7917\n",
      "Epoch 96/1000\n",
      "102/102 [==============================] - 0s 132us/step - loss: 0.5881 - acc: 0.8137 - val_loss: 0.6292 - val_acc: 0.7917\n",
      "Epoch 97/1000\n",
      "102/102 [==============================] - 0s 106us/step - loss: 0.5860 - acc: 0.8235 - val_loss: 0.6278 - val_acc: 0.7917\n",
      "Epoch 98/1000\n",
      "102/102 [==============================] - 0s 102us/step - loss: 0.5839 - acc: 0.8235 - val_loss: 0.6262 - val_acc: 0.7917\n",
      "Epoch 99/1000\n",
      "102/102 [==============================] - 0s 137us/step - loss: 0.5819 - acc: 0.8235 - val_loss: 0.6245 - val_acc: 0.7917\n",
      "Epoch 100/1000\n",
      "102/102 [==============================] - 0s 119us/step - loss: 0.5799 - acc: 0.8235 - val_loss: 0.6232 - val_acc: 0.7917\n",
      "Epoch 101/1000\n",
      "102/102 [==============================] - 0s 138us/step - loss: 0.5778 - acc: 0.8235 - val_loss: 0.6219 - val_acc: 0.7917\n",
      "Epoch 102/1000\n",
      "102/102 [==============================] - 0s 113us/step - loss: 0.5758 - acc: 0.8235 - val_loss: 0.6205 - val_acc: 0.7917\n",
      "Epoch 103/1000\n",
      "102/102 [==============================] - 0s 128us/step - loss: 0.5739 - acc: 0.8235 - val_loss: 0.6188 - val_acc: 0.7917\n",
      "Epoch 104/1000\n",
      "102/102 [==============================] - 0s 113us/step - loss: 0.5719 - acc: 0.8235 - val_loss: 0.6171 - val_acc: 0.7917\n",
      "Epoch 105/1000\n",
      "102/102 [==============================] - 0s 144us/step - loss: 0.5699 - acc: 0.8235 - val_loss: 0.6149 - val_acc: 0.7917\n",
      "Epoch 106/1000\n",
      "102/102 [==============================] - 0s 117us/step - loss: 0.5681 - acc: 0.8235 - val_loss: 0.6130 - val_acc: 0.7917\n",
      "Epoch 107/1000\n",
      "102/102 [==============================] - 0s 126us/step - loss: 0.5662 - acc: 0.8235 - val_loss: 0.6114 - val_acc: 0.7917\n",
      "Epoch 108/1000\n",
      "102/102 [==============================] - 0s 103us/step - loss: 0.5643 - acc: 0.8235 - val_loss: 0.6100 - val_acc: 0.7917\n",
      "Epoch 109/1000\n",
      "102/102 [==============================] - 0s 123us/step - loss: 0.5625 - acc: 0.8235 - val_loss: 0.6086 - val_acc: 0.7917\n",
      "Epoch 110/1000\n",
      "102/102 [==============================] - 0s 117us/step - loss: 0.5608 - acc: 0.8235 - val_loss: 0.6071 - val_acc: 0.7917\n",
      "Epoch 111/1000\n",
      "102/102 [==============================] - 0s 139us/step - loss: 0.5590 - acc: 0.8235 - val_loss: 0.6055 - val_acc: 0.7917\n",
      "Epoch 112/1000\n",
      "102/102 [==============================] - 0s 136us/step - loss: 0.5572 - acc: 0.8235 - val_loss: 0.6038 - val_acc: 0.7917\n",
      "Epoch 113/1000\n",
      "102/102 [==============================] - 0s 117us/step - loss: 0.5552 - acc: 0.8235 - val_loss: 0.6021 - val_acc: 0.7917\n",
      "Epoch 114/1000\n",
      "102/102 [==============================] - 0s 133us/step - loss: 0.5535 - acc: 0.8333 - val_loss: 0.6003 - val_acc: 0.7917\n",
      "Epoch 115/1000\n",
      "102/102 [==============================] - 0s 151us/step - loss: 0.5516 - acc: 0.8431 - val_loss: 0.5986 - val_acc: 0.7917\n",
      "Epoch 116/1000\n",
      "102/102 [==============================] - 0s 115us/step - loss: 0.5499 - acc: 0.8431 - val_loss: 0.5969 - val_acc: 0.7917\n",
      "Epoch 117/1000\n",
      "102/102 [==============================] - 0s 127us/step - loss: 0.5481 - acc: 0.8431 - val_loss: 0.5950 - val_acc: 0.7917\n",
      "Epoch 118/1000\n",
      "102/102 [==============================] - 0s 137us/step - loss: 0.5463 - acc: 0.8431 - val_loss: 0.5931 - val_acc: 0.7917\n",
      "Epoch 119/1000\n",
      "102/102 [==============================] - 0s 119us/step - loss: 0.5445 - acc: 0.8529 - val_loss: 0.5909 - val_acc: 0.7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "102/102 [==============================] - 0s 105us/step - loss: 0.5426 - acc: 0.8529 - val_loss: 0.5885 - val_acc: 0.7917\n",
      "Epoch 121/1000\n",
      "102/102 [==============================] - 0s 135us/step - loss: 0.5405 - acc: 0.8627 - val_loss: 0.5863 - val_acc: 0.7917\n",
      "Epoch 122/1000\n",
      "102/102 [==============================] - 0s 112us/step - loss: 0.5387 - acc: 0.8627 - val_loss: 0.5842 - val_acc: 0.7917\n",
      "Epoch 123/1000\n",
      "102/102 [==============================] - 0s 110us/step - loss: 0.5369 - acc: 0.8627 - val_loss: 0.5822 - val_acc: 0.7917\n",
      "Epoch 124/1000\n",
      "102/102 [==============================] - 0s 132us/step - loss: 0.5349 - acc: 0.8627 - val_loss: 0.5807 - val_acc: 0.8333\n",
      "Epoch 125/1000\n",
      "102/102 [==============================] - 0s 158us/step - loss: 0.5331 - acc: 0.8627 - val_loss: 0.5789 - val_acc: 0.8333\n",
      "Epoch 126/1000\n",
      "102/102 [==============================] - 0s 130us/step - loss: 0.5312 - acc: 0.8627 - val_loss: 0.5773 - val_acc: 0.8333\n",
      "Epoch 127/1000\n",
      "102/102 [==============================] - 0s 150us/step - loss: 0.5293 - acc: 0.8627 - val_loss: 0.5755 - val_acc: 0.8333\n",
      "Epoch 128/1000\n",
      "102/102 [==============================] - 0s 149us/step - loss: 0.5274 - acc: 0.8627 - val_loss: 0.5739 - val_acc: 0.8333\n",
      "Epoch 129/1000\n",
      "102/102 [==============================] - 0s 120us/step - loss: 0.5254 - acc: 0.8627 - val_loss: 0.5720 - val_acc: 0.8333\n",
      "Epoch 130/1000\n",
      "102/102 [==============================] - 0s 125us/step - loss: 0.5234 - acc: 0.8627 - val_loss: 0.5696 - val_acc: 0.8333\n",
      "Epoch 131/1000\n",
      "102/102 [==============================] - 0s 122us/step - loss: 0.5213 - acc: 0.8627 - val_loss: 0.5673 - val_acc: 0.8333\n",
      "Epoch 132/1000\n",
      "102/102 [==============================] - 0s 130us/step - loss: 0.5194 - acc: 0.8627 - val_loss: 0.5651 - val_acc: 0.8333\n",
      "Epoch 133/1000\n",
      "102/102 [==============================] - 0s 159us/step - loss: 0.5173 - acc: 0.8627 - val_loss: 0.5626 - val_acc: 0.8333\n",
      "Epoch 134/1000\n",
      "102/102 [==============================] - 0s 149us/step - loss: 0.5151 - acc: 0.8627 - val_loss: 0.5602 - val_acc: 0.8333\n",
      "Epoch 135/1000\n",
      "102/102 [==============================] - 0s 145us/step - loss: 0.5130 - acc: 0.8627 - val_loss: 0.5580 - val_acc: 0.8333\n",
      "Epoch 136/1000\n",
      "102/102 [==============================] - 0s 150us/step - loss: 0.5111 - acc: 0.8627 - val_loss: 0.5561 - val_acc: 0.8333\n",
      "Epoch 137/1000\n",
      "102/102 [==============================] - 0s 118us/step - loss: 0.5091 - acc: 0.8725 - val_loss: 0.5543 - val_acc: 0.8333\n",
      "Epoch 138/1000\n",
      "102/102 [==============================] - 0s 133us/step - loss: 0.5071 - acc: 0.8725 - val_loss: 0.5530 - val_acc: 0.8333\n",
      "Epoch 139/1000\n",
      "102/102 [==============================] - 0s 139us/step - loss: 0.5052 - acc: 0.8725 - val_loss: 0.5514 - val_acc: 0.8333\n",
      "Epoch 140/1000\n",
      "102/102 [==============================] - 0s 125us/step - loss: 0.5032 - acc: 0.8725 - val_loss: 0.5491 - val_acc: 0.8333\n",
      "Epoch 141/1000\n",
      "102/102 [==============================] - 0s 147us/step - loss: 0.5011 - acc: 0.8725 - val_loss: 0.5469 - val_acc: 0.8333\n",
      "Epoch 142/1000\n",
      "102/102 [==============================] - 0s 111us/step - loss: 0.4990 - acc: 0.8725 - val_loss: 0.5448 - val_acc: 0.8333\n",
      "Epoch 143/1000\n",
      "102/102 [==============================] - 0s 157us/step - loss: 0.4970 - acc: 0.8725 - val_loss: 0.5426 - val_acc: 0.8333\n",
      "Epoch 144/1000\n",
      "102/102 [==============================] - 0s 123us/step - loss: 0.4950 - acc: 0.8725 - val_loss: 0.5405 - val_acc: 0.8750\n",
      "Epoch 145/1000\n",
      "102/102 [==============================] - 0s 112us/step - loss: 0.4932 - acc: 0.8725 - val_loss: 0.5382 - val_acc: 0.8750\n",
      "Epoch 146/1000\n",
      "102/102 [==============================] - 0s 113us/step - loss: 0.4911 - acc: 0.8725 - val_loss: 0.5355 - val_acc: 0.8750\n",
      "Epoch 147/1000\n",
      "102/102 [==============================] - 0s 117us/step - loss: 0.4890 - acc: 0.8725 - val_loss: 0.5324 - val_acc: 0.8750\n",
      "Epoch 148/1000\n",
      "102/102 [==============================] - 0s 127us/step - loss: 0.4873 - acc: 0.8725 - val_loss: 0.5295 - val_acc: 0.8750\n",
      "Epoch 149/1000\n",
      "102/102 [==============================] - 0s 105us/step - loss: 0.4851 - acc: 0.8725 - val_loss: 0.5270 - val_acc: 0.8750\n",
      "Epoch 150/1000\n",
      "102/102 [==============================] - 0s 118us/step - loss: 0.4832 - acc: 0.8627 - val_loss: 0.5248 - val_acc: 0.8750\n",
      "Epoch 151/1000\n",
      "102/102 [==============================] - 0s 108us/step - loss: 0.4813 - acc: 0.8627 - val_loss: 0.5229 - val_acc: 0.8750\n",
      "Epoch 152/1000\n",
      "102/102 [==============================] - 0s 175us/step - loss: 0.4794 - acc: 0.8627 - val_loss: 0.5210 - val_acc: 0.8750\n",
      "Epoch 153/1000\n",
      "102/102 [==============================] - 0s 155us/step - loss: 0.4776 - acc: 0.8725 - val_loss: 0.5189 - val_acc: 0.8750\n",
      "Epoch 154/1000\n",
      "102/102 [==============================] - 0s 105us/step - loss: 0.4758 - acc: 0.8725 - val_loss: 0.5172 - val_acc: 0.8750\n",
      "Epoch 155/1000\n",
      "102/102 [==============================] - 0s 120us/step - loss: 0.4740 - acc: 0.8725 - val_loss: 0.5155 - val_acc: 0.8750\n",
      "Epoch 156/1000\n",
      "102/102 [==============================] - 0s 104us/step - loss: 0.4723 - acc: 0.8725 - val_loss: 0.5139 - val_acc: 0.8750\n",
      "Epoch 157/1000\n",
      "102/102 [==============================] - 0s 109us/step - loss: 0.4706 - acc: 0.8725 - val_loss: 0.5124 - val_acc: 0.8750\n",
      "Epoch 158/1000\n",
      "102/102 [==============================] - 0s 112us/step - loss: 0.4689 - acc: 0.8725 - val_loss: 0.5107 - val_acc: 0.8750\n",
      "Epoch 159/1000\n",
      "102/102 [==============================] - 0s 138us/step - loss: 0.4672 - acc: 0.8725 - val_loss: 0.5091 - val_acc: 0.8750\n",
      "Epoch 160/1000\n",
      "102/102 [==============================] - 0s 121us/step - loss: 0.4655 - acc: 0.8725 - val_loss: 0.5076 - val_acc: 0.8750\n",
      "Epoch 161/1000\n",
      "102/102 [==============================] - 0s 106us/step - loss: 0.4638 - acc: 0.8725 - val_loss: 0.5058 - val_acc: 0.8750\n",
      "Epoch 162/1000\n",
      "102/102 [==============================] - 0s 138us/step - loss: 0.4620 - acc: 0.8725 - val_loss: 0.5037 - val_acc: 0.8750\n",
      "Epoch 163/1000\n",
      "102/102 [==============================] - 0s 132us/step - loss: 0.4603 - acc: 0.8824 - val_loss: 0.5008 - val_acc: 0.8750\n",
      "Epoch 164/1000\n",
      "102/102 [==============================] - 0s 123us/step - loss: 0.4581 - acc: 0.8824 - val_loss: 0.4986 - val_acc: 0.8750\n",
      "Epoch 165/1000\n",
      "102/102 [==============================] - 0s 167us/step - loss: 0.4565 - acc: 0.8824 - val_loss: 0.4961 - val_acc: 0.8750\n",
      "Epoch 166/1000\n",
      "102/102 [==============================] - 0s 110us/step - loss: 0.4548 - acc: 0.8824 - val_loss: 0.4936 - val_acc: 0.8750\n",
      "Epoch 167/1000\n",
      "102/102 [==============================] - 0s 110us/step - loss: 0.4532 - acc: 0.8824 - val_loss: 0.4911 - val_acc: 0.8750\n",
      "Epoch 168/1000\n",
      "102/102 [==============================] - 0s 153us/step - loss: 0.4513 - acc: 0.8824 - val_loss: 0.4894 - val_acc: 0.8750\n",
      "Epoch 169/1000\n",
      "102/102 [==============================] - 0s 120us/step - loss: 0.4497 - acc: 0.8824 - val_loss: 0.4875 - val_acc: 0.8750\n",
      "Epoch 170/1000\n",
      "102/102 [==============================] - 0s 129us/step - loss: 0.4480 - acc: 0.8824 - val_loss: 0.4856 - val_acc: 0.8750\n",
      "Epoch 171/1000\n",
      "102/102 [==============================] - 0s 111us/step - loss: 0.4464 - acc: 0.8824 - val_loss: 0.4837 - val_acc: 0.8750\n",
      "Epoch 172/1000\n",
      "102/102 [==============================] - 0s 140us/step - loss: 0.4446 - acc: 0.8824 - val_loss: 0.4820 - val_acc: 0.8750\n",
      "Epoch 173/1000\n",
      "102/102 [==============================] - 0s 102us/step - loss: 0.4429 - acc: 0.8824 - val_loss: 0.4804 - val_acc: 0.8750\n",
      "Epoch 174/1000\n",
      "102/102 [==============================] - 0s 140us/step - loss: 0.4413 - acc: 0.8824 - val_loss: 0.4791 - val_acc: 0.8750\n",
      "Epoch 175/1000\n",
      "102/102 [==============================] - 0s 107us/step - loss: 0.4395 - acc: 0.8824 - val_loss: 0.4774 - val_acc: 0.8750\n",
      "Epoch 176/1000\n",
      "102/102 [==============================] - 0s 140us/step - loss: 0.4378 - acc: 0.8824 - val_loss: 0.4755 - val_acc: 0.8750\n",
      "Epoch 177/1000\n",
      "102/102 [==============================] - 0s 117us/step - loss: 0.4360 - acc: 0.8824 - val_loss: 0.4737 - val_acc: 0.8750\n",
      "Epoch 178/1000\n",
      "102/102 [==============================] - 0s 129us/step - loss: 0.4342 - acc: 0.8922 - val_loss: 0.4720 - val_acc: 0.8750\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 114us/step - loss: 0.4325 - acc: 0.8922 - val_loss: 0.4701 - val_acc: 0.8750\n",
      "Epoch 180/1000\n",
      "102/102 [==============================] - 0s 131us/step - loss: 0.4307 - acc: 0.9020 - val_loss: 0.4682 - val_acc: 0.9167\n",
      "Epoch 181/1000\n",
      "102/102 [==============================] - 0s 128us/step - loss: 0.4291 - acc: 0.9020 - val_loss: 0.4669 - val_acc: 0.9167\n",
      "Epoch 182/1000\n",
      "102/102 [==============================] - 0s 136us/step - loss: 0.4273 - acc: 0.9020 - val_loss: 0.4649 - val_acc: 0.9167\n",
      "Epoch 183/1000\n",
      "102/102 [==============================] - 0s 148us/step - loss: 0.4256 - acc: 0.9020 - val_loss: 0.4625 - val_acc: 0.9167\n",
      "Epoch 184/1000\n",
      "102/102 [==============================] - 0s 130us/step - loss: 0.4235 - acc: 0.9118 - val_loss: 0.4602 - val_acc: 0.9167\n",
      "Epoch 185/1000\n",
      "102/102 [==============================] - 0s 137us/step - loss: 0.4217 - acc: 0.9314 - val_loss: 0.4578 - val_acc: 0.9167\n",
      "Epoch 186/1000\n",
      "102/102 [==============================] - 0s 163us/step - loss: 0.4198 - acc: 0.9314 - val_loss: 0.4560 - val_acc: 0.9167\n",
      "Epoch 187/1000\n",
      "102/102 [==============================] - 0s 147us/step - loss: 0.4181 - acc: 0.9314 - val_loss: 0.4537 - val_acc: 0.9167\n",
      "Epoch 188/1000\n",
      "102/102 [==============================] - 0s 146us/step - loss: 0.4162 - acc: 0.9314 - val_loss: 0.4514 - val_acc: 0.9167\n",
      "Epoch 189/1000\n",
      "102/102 [==============================] - 0s 164us/step - loss: 0.4145 - acc: 0.9314 - val_loss: 0.4496 - val_acc: 0.9167\n",
      "Epoch 190/1000\n",
      "102/102 [==============================] - 0s 134us/step - loss: 0.4128 - acc: 0.9314 - val_loss: 0.4482 - val_acc: 0.9167\n",
      "Epoch 191/1000\n",
      "102/102 [==============================] - 0s 144us/step - loss: 0.4112 - acc: 0.9314 - val_loss: 0.4473 - val_acc: 0.9167\n",
      "Epoch 192/1000\n",
      "102/102 [==============================] - 0s 147us/step - loss: 0.4096 - acc: 0.9314 - val_loss: 0.4461 - val_acc: 0.9167\n",
      "Epoch 193/1000\n",
      "102/102 [==============================] - 0s 131us/step - loss: 0.4082 - acc: 0.9314 - val_loss: 0.4453 - val_acc: 0.9167\n",
      "Epoch 194/1000\n",
      "102/102 [==============================] - 0s 153us/step - loss: 0.4067 - acc: 0.9314 - val_loss: 0.4448 - val_acc: 0.9167\n",
      "Epoch 195/1000\n",
      "102/102 [==============================] - 0s 136us/step - loss: 0.4053 - acc: 0.9314 - val_loss: 0.4443 - val_acc: 0.9167\n",
      "Epoch 196/1000\n",
      "102/102 [==============================] - 0s 124us/step - loss: 0.4041 - acc: 0.9314 - val_loss: 0.4437 - val_acc: 0.9167\n",
      "Epoch 197/1000\n",
      "102/102 [==============================] - 0s 137us/step - loss: 0.4027 - acc: 0.9314 - val_loss: 0.4426 - val_acc: 0.9167\n",
      "Epoch 198/1000\n",
      "102/102 [==============================] - 0s 138us/step - loss: 0.4014 - acc: 0.9314 - val_loss: 0.4414 - val_acc: 0.9167\n",
      "Epoch 199/1000\n",
      "102/102 [==============================] - 0s 163us/step - loss: 0.3999 - acc: 0.9412 - val_loss: 0.4395 - val_acc: 0.9167\n",
      "Epoch 200/1000\n",
      "102/102 [==============================] - 0s 144us/step - loss: 0.3985 - acc: 0.9412 - val_loss: 0.4373 - val_acc: 0.9167\n",
      "Epoch 201/1000\n",
      "102/102 [==============================] - 0s 118us/step - loss: 0.3969 - acc: 0.9412 - val_loss: 0.4356 - val_acc: 0.9167\n",
      "Epoch 202/1000\n",
      "102/102 [==============================] - 0s 132us/step - loss: 0.3953 - acc: 0.9412 - val_loss: 0.4343 - val_acc: 0.9167\n",
      "Epoch 203/1000\n",
      "102/102 [==============================] - 0s 92us/step - loss: 0.3938 - acc: 0.9412 - val_loss: 0.4324 - val_acc: 0.9167\n",
      "Epoch 204/1000\n",
      "102/102 [==============================] - 0s 140us/step - loss: 0.3921 - acc: 0.9412 - val_loss: 0.4300 - val_acc: 0.9167\n",
      "Epoch 205/1000\n",
      "102/102 [==============================] - 0s 95us/step - loss: 0.3905 - acc: 0.9412 - val_loss: 0.4277 - val_acc: 0.9167\n",
      "Epoch 206/1000\n",
      "102/102 [==============================] - 0s 144us/step - loss: 0.3891 - acc: 0.9412 - val_loss: 0.4252 - val_acc: 0.9167\n",
      "Epoch 207/1000\n",
      "102/102 [==============================] - 0s 130us/step - loss: 0.3875 - acc: 0.9412 - val_loss: 0.4231 - val_acc: 0.9167\n",
      "Epoch 208/1000\n",
      "102/102 [==============================] - 0s 132us/step - loss: 0.3860 - acc: 0.9412 - val_loss: 0.4222 - val_acc: 0.9167\n",
      "Epoch 209/1000\n",
      "102/102 [==============================] - 0s 140us/step - loss: 0.3846 - acc: 0.9412 - val_loss: 0.4210 - val_acc: 0.9167\n",
      "Epoch 210/1000\n",
      "102/102 [==============================] - 0s 121us/step - loss: 0.3832 - acc: 0.9412 - val_loss: 0.4191 - val_acc: 0.9167\n",
      "Epoch 211/1000\n",
      "102/102 [==============================] - 0s 157us/step - loss: 0.3817 - acc: 0.9412 - val_loss: 0.4172 - val_acc: 0.9167\n",
      "Epoch 212/1000\n",
      "102/102 [==============================] - 0s 130us/step - loss: 0.3803 - acc: 0.9510 - val_loss: 0.4149 - val_acc: 0.9167\n",
      "Epoch 213/1000\n",
      "102/102 [==============================] - 0s 90us/step - loss: 0.3788 - acc: 0.9510 - val_loss: 0.4126 - val_acc: 0.9167\n",
      "Epoch 214/1000\n",
      "102/102 [==============================] - 0s 151us/step - loss: 0.3774 - acc: 0.9510 - val_loss: 0.4104 - val_acc: 0.9167\n",
      "Epoch 215/1000\n",
      "102/102 [==============================] - 0s 144us/step - loss: 0.3759 - acc: 0.9412 - val_loss: 0.4082 - val_acc: 0.9167\n",
      "Epoch 216/1000\n",
      "102/102 [==============================] - 0s 126us/step - loss: 0.3746 - acc: 0.9412 - val_loss: 0.4064 - val_acc: 0.9167\n",
      "Epoch 217/1000\n",
      "102/102 [==============================] - 0s 126us/step - loss: 0.3732 - acc: 0.9412 - val_loss: 0.4050 - val_acc: 0.9167\n",
      "Epoch 218/1000\n",
      "102/102 [==============================] - 0s 132us/step - loss: 0.3719 - acc: 0.9510 - val_loss: 0.4042 - val_acc: 0.9167\n",
      "Epoch 219/1000\n",
      "102/102 [==============================] - 0s 118us/step - loss: 0.3707 - acc: 0.9510 - val_loss: 0.4041 - val_acc: 0.9167\n",
      "Epoch 220/1000\n",
      "102/102 [==============================] - 0s 82us/step - loss: 0.3694 - acc: 0.9510 - val_loss: 0.4038 - val_acc: 0.9167\n",
      "Epoch 221/1000\n",
      "102/102 [==============================] - 0s 118us/step - loss: 0.3682 - acc: 0.9510 - val_loss: 0.4037 - val_acc: 0.9167\n",
      "Epoch 222/1000\n",
      "102/102 [==============================] - 0s 110us/step - loss: 0.3671 - acc: 0.9510 - val_loss: 0.4038 - val_acc: 0.9167\n",
      "Epoch 223/1000\n",
      "102/102 [==============================] - 0s 94us/step - loss: 0.3659 - acc: 0.9510 - val_loss: 0.4026 - val_acc: 0.9167\n",
      "Epoch 224/1000\n",
      "102/102 [==============================] - 0s 116us/step - loss: 0.3646 - acc: 0.9510 - val_loss: 0.4010 - val_acc: 0.9167\n",
      "Epoch 225/1000\n",
      "102/102 [==============================] - 0s 123us/step - loss: 0.3635 - acc: 0.9510 - val_loss: 0.3990 - val_acc: 0.9167\n",
      "Epoch 226/1000\n",
      "102/102 [==============================] - 0s 138us/step - loss: 0.3622 - acc: 0.9510 - val_loss: 0.3974 - val_acc: 0.9167\n",
      "Epoch 227/1000\n",
      "102/102 [==============================] - 0s 113us/step - loss: 0.3611 - acc: 0.9510 - val_loss: 0.3952 - val_acc: 0.9167\n",
      "Epoch 228/1000\n",
      "102/102 [==============================] - 0s 117us/step - loss: 0.3598 - acc: 0.9510 - val_loss: 0.3931 - val_acc: 0.9167\n",
      "Epoch 229/1000\n",
      "102/102 [==============================] - 0s 105us/step - loss: 0.3591 - acc: 0.9510 - val_loss: 0.3913 - val_acc: 0.9167\n",
      "Epoch 230/1000\n",
      "102/102 [==============================] - 0s 143us/step - loss: 0.3579 - acc: 0.9510 - val_loss: 0.3903 - val_acc: 0.9167\n",
      "Epoch 231/1000\n",
      "102/102 [==============================] - 0s 113us/step - loss: 0.3568 - acc: 0.9510 - val_loss: 0.3892 - val_acc: 0.9167\n",
      "Epoch 232/1000\n",
      "102/102 [==============================] - 0s 124us/step - loss: 0.3557 - acc: 0.9608 - val_loss: 0.3878 - val_acc: 0.9167\n",
      "Epoch 233/1000\n",
      "102/102 [==============================] - 0s 156us/step - loss: 0.3548 - acc: 0.9608 - val_loss: 0.3867 - val_acc: 0.9167\n",
      "Epoch 234/1000\n",
      "102/102 [==============================] - 0s 121us/step - loss: 0.3537 - acc: 0.9608 - val_loss: 0.3861 - val_acc: 0.9167\n",
      "Epoch 235/1000\n",
      "102/102 [==============================] - 0s 128us/step - loss: 0.3526 - acc: 0.9608 - val_loss: 0.3858 - val_acc: 0.9167\n",
      "Epoch 236/1000\n",
      "102/102 [==============================] - 0s 104us/step - loss: 0.3515 - acc: 0.9608 - val_loss: 0.3857 - val_acc: 0.9167\n",
      "Epoch 237/1000\n",
      "102/102 [==============================] - 0s 131us/step - loss: 0.3504 - acc: 0.9608 - val_loss: 0.3848 - val_acc: 0.9167\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 94us/step - loss: 0.3493 - acc: 0.9608 - val_loss: 0.3835 - val_acc: 0.9167\n",
      "Epoch 239/1000\n",
      "102/102 [==============================] - 0s 104us/step - loss: 0.3482 - acc: 0.9608 - val_loss: 0.3819 - val_acc: 0.9167\n",
      "Epoch 240/1000\n",
      "102/102 [==============================] - 0s 130us/step - loss: 0.3472 - acc: 0.9608 - val_loss: 0.3811 - val_acc: 0.9167\n",
      "Epoch 241/1000\n",
      "102/102 [==============================] - 0s 140us/step - loss: 0.3461 - acc: 0.9706 - val_loss: 0.3801 - val_acc: 0.9167\n",
      "Epoch 242/1000\n",
      "102/102 [==============================] - 0s 106us/step - loss: 0.3451 - acc: 0.9706 - val_loss: 0.3789 - val_acc: 0.9167\n",
      "Epoch 243/1000\n",
      "102/102 [==============================] - 0s 97us/step - loss: 0.3441 - acc: 0.9706 - val_loss: 0.3776 - val_acc: 0.9167\n",
      "Epoch 244/1000\n",
      "102/102 [==============================] - 0s 152us/step - loss: 0.3432 - acc: 0.9706 - val_loss: 0.3765 - val_acc: 0.9167\n",
      "Epoch 245/1000\n",
      "102/102 [==============================] - 0s 171us/step - loss: 0.3421 - acc: 0.9706 - val_loss: 0.3754 - val_acc: 0.9167\n",
      "Epoch 246/1000\n",
      "102/102 [==============================] - 0s 133us/step - loss: 0.3411 - acc: 0.9706 - val_loss: 0.3747 - val_acc: 0.9583\n",
      "Epoch 247/1000\n",
      "102/102 [==============================] - 0s 147us/step - loss: 0.3401 - acc: 0.9706 - val_loss: 0.3739 - val_acc: 0.9583\n",
      "Epoch 248/1000\n",
      "102/102 [==============================] - 0s 142us/step - loss: 0.3391 - acc: 0.9706 - val_loss: 0.3736 - val_acc: 0.9583\n",
      "Epoch 249/1000\n",
      "102/102 [==============================] - 0s 133us/step - loss: 0.3381 - acc: 0.9706 - val_loss: 0.3727 - val_acc: 0.9583\n",
      "Epoch 250/1000\n",
      "102/102 [==============================] - 0s 122us/step - loss: 0.3372 - acc: 0.9804 - val_loss: 0.3721 - val_acc: 0.9583\n",
      "Epoch 251/1000\n",
      "102/102 [==============================] - 0s 158us/step - loss: 0.3363 - acc: 0.9804 - val_loss: 0.3712 - val_acc: 0.9583\n",
      "Epoch 252/1000\n",
      "102/102 [==============================] - 0s 152us/step - loss: 0.3354 - acc: 0.9804 - val_loss: 0.3698 - val_acc: 0.9583\n",
      "Epoch 253/1000\n",
      "102/102 [==============================] - 0s 134us/step - loss: 0.3345 - acc: 0.9804 - val_loss: 0.3688 - val_acc: 0.9583\n",
      "Epoch 254/1000\n",
      "102/102 [==============================] - 0s 138us/step - loss: 0.3336 - acc: 0.9804 - val_loss: 0.3680 - val_acc: 0.9583\n",
      "Epoch 255/1000\n",
      "102/102 [==============================] - 0s 113us/step - loss: 0.3327 - acc: 0.9804 - val_loss: 0.3664 - val_acc: 0.9583\n",
      "Epoch 256/1000\n",
      "102/102 [==============================] - 0s 145us/step - loss: 0.3320 - acc: 0.9804 - val_loss: 0.3651 - val_acc: 0.9583\n",
      "Epoch 257/1000\n",
      "102/102 [==============================] - 0s 120us/step - loss: 0.3312 - acc: 0.9804 - val_loss: 0.3644 - val_acc: 0.9583\n",
      "Epoch 258/1000\n",
      "102/102 [==============================] - 0s 139us/step - loss: 0.3304 - acc: 0.9804 - val_loss: 0.3642 - val_acc: 0.9583\n",
      "Epoch 259/1000\n",
      "102/102 [==============================] - 0s 136us/step - loss: 0.3295 - acc: 0.9804 - val_loss: 0.3640 - val_acc: 0.9583\n",
      "Epoch 260/1000\n",
      "102/102 [==============================] - 0s 131us/step - loss: 0.3287 - acc: 0.9804 - val_loss: 0.3646 - val_acc: 0.9583\n",
      "Epoch 261/1000\n",
      "102/102 [==============================] - 0s 137us/step - loss: 0.3279 - acc: 0.9804 - val_loss: 0.3652 - val_acc: 0.9583\n",
      "Epoch 262/1000\n",
      "102/102 [==============================] - 0s 134us/step - loss: 0.3271 - acc: 0.9804 - val_loss: 0.3657 - val_acc: 0.9583\n",
      "Epoch 263/1000\n",
      "102/102 [==============================] - 0s 137us/step - loss: 0.3264 - acc: 0.9804 - val_loss: 0.3668 - val_acc: 0.9583\n",
      "Epoch 264/1000\n",
      "102/102 [==============================] - 0s 146us/step - loss: 0.3258 - acc: 0.9804 - val_loss: 0.3676 - val_acc: 0.9583\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1000, validation_data=[X_val, y_val], callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.round(model.predict(X_test).argmax(axis=1).reshape(-1,))\n",
    "accuracy_score(pred, y_test.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat = confusion_matrix(pred, y_test.argmax(axis=1))\n",
    "cm = mat / np.sum(mat, axis=1)\n",
    "plot_confusion_matrix(cm, classes=['setosa', 'versicolor', 'virginica'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()\n",
    "np.save('relu_weights', weights, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
